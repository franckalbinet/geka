# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_loading.ipynb.

# %% auto 0
__all__ = ['PATH_OSSL_ALL_L0_V1_2', 'PATH_OSSL_ALL_L1_V1_2', 'download', 'load_ossl']

# %% ../nbs/00_loading.ipynb 3
from pathlib import Path
from typing import Union, List
import fastdownload as fd
import fastcore.all as fc

import pandas as pd

import warnings
warnings.filterwarnings('ignore')

# %% ../nbs/00_loading.ipynb 4
PATH_OSSL_ALL_L0_V1_2 = 'https://storage.googleapis.com/soilspec4gg-public/ossl_all_L0_v1.2.csv.gz'
PATH_OSSL_ALL_L1_V1_2 = 'https://storage.googleapis.com/soilspec4gg-public/ossl_all_L0_v1.2.csv.gz'

# %% ../nbs/00_loading.ipynb 5
def download(url, dest):
    "Download `given` url into `dest` (creates it on the way if does not exist) "
    if not dest.exists(): fc.mkdir(dest, parents=True)
    return fd.download_url(url, dest)

# %% ../nbs/00_loading.ipynb 6
def load_ossl(analytes: Union[str, List[str]], # Using OSSL's analytes naming conventions
              dest:Path=Path.home() / '.geka/data/ossl', # directory containing the data
              ):
    "Load all available OSSL data and filter it by analytes of interest"
    
    url = PATH_OSSL_ALL_L1_V1_2
    fname = dest / Path(PATH_OSSL_ALL_L1_V1_2).name
    if not fname.exists(): 
        print('Downloading & saving to: ', str(fname))
        download(url, dest)
    
    print('Reading & selecting data ...')
    
    df = pd.read_csv(fname, compression='infer', low_memory=True)
            
    analytes = [analytes] if isinstance(analytes, str) else analytes
    cols_not_nan = ['longitude.point_wgs84_dd', 'latitude.point_wgs84_dd', 'observation.date.begin_iso.8601_yyyy.mm.dd']
    
    df = df.dropna(subset=analytes+cols_not_nan)
    
    metadata_of_interest = ['dataset.code_ascii_txt', 'id.layer_local_c', 'id.project_ascii_txt', 
                            'layer.upper.depth_usda_cm', 'layer.lower.depth_usda_cm']
    
    return df[metadata_of_interest + cols_not_nan + analytes]
